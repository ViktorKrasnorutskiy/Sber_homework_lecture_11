{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(link, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Wall time: 1.19 s\n",
      "0.5659787367104441 \n",
      "\n",
      "BaggingClassifier(n_estimators=100)\n",
      "Wall time: 2.36 s\n",
      "0.5628517823639775 \n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Wall time: 51 ms\n",
      "0.45278298936835526 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "clfs = [RandomForestClassifier(n_estimators=100), BaggingClassifier(n_estimators=100), DecisionTreeClassifier()]\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    %time cvs = cross_val_score(clf, X, y, scoring='accuracy', cv=3).mean()\n",
    "    print(cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат по метрике accuracy у RandomForestClassifier почти такой-же как и у BaggingClassifier, но скорость обучения быстрее в ~2 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, test_size=.3, size=1, seed=42):\n",
    "    df_res = df.sample(int(df.shape[0]*size)).copy() if size != 1 else df.copy()\n",
    "    X_res, y_res = df_res.iloc[:,:-1], df_res.iloc[:,-1]\n",
    "    X_res_train, X_res_test, y_res_train, y_res_test = train_test_split(X_res, y_res, test_size=test_size, random_state=seed)\n",
    "    return df_res, X_res, y_res, X_res_train, X_res_test, y_res_train, y_res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12) (1599, 11) (1119, 11) (480, 11)\n"
     ]
    }
   ],
   "source": [
    "df, X, y, X_train, X_test, y_train, y_test = split_df(data)\n",
    "print(df.shape, X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = [10, 50, 100] + [n for n in range(200,5001,200)]\n",
    "scores = []\n",
    "\n",
    "for n in N:\n",
    "    clf = RandomForestClassifier(n_estimators=int(n), n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    scores.append({'n':int(n), 'score_test':score_test, 'score_train':score_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fe325536a0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "plt.plot(scores_df.n, scores_df.score_test)\n",
    "#plt.plot(scores_df.n, scores_df.score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Wall time: 12.6 s\n",
      "0.5659776645768024 \n",
      "\n",
      "XGBClassifier\n",
      "Wall time: 3.16 s\n",
      "0.5472335423197492 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "clfs = [{'name':'GradientBoostingClassifier', 'model':GradientBoostingClassifier()}, \n",
    "        {'name':'XGBClassifier', 'model':XGBClassifier(objective='multi:softprob', eval_metric='mlogloss')}]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf_name = clf['name']\n",
    "    model = clf['model']\n",
    "    print(clf_name)\n",
    "    %time cvs = cross_val_score(model, X, y, scoring=\"accuracy\", cv=5).mean()\n",
    "    print(cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'presort', 'random_state', 'subsample', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['objective', 'use_label_encoder', 'base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'gpu_id', 'importance_type', 'interaction_constraints', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'monotone_constraints', 'n_estimators', 'n_jobs', 'num_parallel_tree', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'subsample', 'tree_method', 'validate_parameters', 'verbosity'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 2s\n",
      "GradientBoostingClassifier\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 30}\n",
      "Wall time: 6.79 s\n",
      "XGBClassifier\n",
      "{'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 20, 'objective': 'multi:softprob'}\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'clf': GradientBoostingClassifier,\n",
    "        'params': [{\n",
    "            'criterion': ['friedman_mse', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30], \n",
    "            'max_depth': [2, 3, 4]\n",
    "        }]\n",
    "    }, {\n",
    "        'clf': XGBClassifier,\n",
    "        'params': [{\n",
    "            'objective': ['multi:softprob'],\n",
    "            'eval_metric': ['mlogloss', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4]\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_dfs = []\n",
    "\n",
    "for model in models:\n",
    "    clf_name = model['clf'].__name__\n",
    "    clf = model['clf']\n",
    "    params = model['params']\n",
    "    %time search = GridSearchCV(clf(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(X, y)\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    cv_df['clf_name'] = clf_name\n",
    "    cv_dfs.append(cv_df)\n",
    "    print(clf_name)\n",
    "    print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_eval_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.402767</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlogloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.557849</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>mlogloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.389658</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         clf_name  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "61  XGBClassifier         0.585991       0.402767         0.001334   \n",
       "63  XGBClassifier         0.557849       0.096728         0.005342   \n",
       "88  XGBClassifier         0.585991       0.389658         0.005210   \n",
       "\n",
       "   param_criterion param_learning_rate param_max_depth param_n_estimators  \\\n",
       "61             NaN                 0.1               4                 20   \n",
       "63             NaN                 0.5               2                 10   \n",
       "88             NaN                 0.1               4                 20   \n",
       "\n",
       "   param_eval_metric  \n",
       "61          mlogloss  \n",
       "63          mlogloss  \n",
       "88               mae  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_df = pd.concat(cv_dfs).reset_index(drop=True)\n",
    "best_models = cvs_df[\n",
    "        (cvs_df.mean_fit_time == cvs_df.mean_fit_time.min()) |\n",
    "        #(cvs_df.mean_score_time == cvs_df.mean_score_time.min()) | \n",
    "        (cvs_df.mean_test_score == cvs_df.mean_test_score.max())]\n",
    "best_models = best_models[[\n",
    "        'clf_name',\n",
    "        'mean_test_score',\n",
    "        'mean_fit_time',\n",
    "        'mean_score_time',\n",
    "        'param_criterion',\n",
    "        'param_learning_rate',\n",
    "        'param_max_depth',\n",
    "        'param_n_estimators',\n",
    "        'param_eval_metric'\n",
    "]]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score -  0.5472335423197492 \n",
      "\n",
      "Wall time: 1.61 s\n",
      "score -  0.625\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(), X, y, scoring=\"accuracy\", cv=cv).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')\n",
    "\n",
    "%time score = model().fit(X_train, y_train).score(X_test, y_test)\n",
    "print('score - ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score -  0.5472335423197492 \n",
      "\n",
      "Wall time: 468 ms\n",
      "score -  0.65625\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(objective='multi:softprob', eval_metric='mlogloss'), X, y, scoring=\"accuracy\", cv=cv).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')\n",
    "\n",
    "%time score = model(objective='multi:softprob', eval_metric='mlogloss').fit(X_train, y_train).score(X_test, y_test)\n",
    "print('score - ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score -  0.5472335423197492 \n",
      "\n",
      "Wall time: 415 ms\n",
      "score -  0.675\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(), X, y, scoring=\"accuracy\", cv=cv).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')\n",
    "\n",
    "%time score = model().fit(X_train, y_train).score(X_test, y_test)\n",
    "print('score - ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score -  0.5472335423197492 \n",
      "\n",
      "Wall time: 6.99 s\n",
      "score -  0.6729166666666667\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(verbose=False), X, y, scoring=\"accuracy\", cv=cv).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')\n",
    "\n",
    "%time score = model(verbose=False).fit(X_train, y_train).score(X_test, y_test)\n",
    "print('score - ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoostClassifier(verbose=False).fit(X,y).get_all_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "Wall time: 5.24 s\n",
      "LGBMClassifier\n",
      "{'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 20, 'objective': 'multi:softprob'} \n",
      "\n",
      "Wall time: 3.16 s\n",
      "CatBoostClassifier\n",
      "{'eval_metric': 'MultiClass', 'learning_rate': 0.1, 'loss_function': 'MultiClass', 'max_depth': 4, 'n_estimators': 30, 'verbose': False} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'clf': LGBMClassifier,\n",
    "        'params': [{\n",
    "            'objective': ['multi:softprob'],\n",
    "            'eval_metric': ['mlogloss', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4]}]\n",
    "    }, {\n",
    "        'clf': CatBoostClassifier,\n",
    "        'params': [{\n",
    "            'loss_function': ['MultiClass'],\n",
    "            'eval_metric': ['MultiClass'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4],\n",
    "            'verbose': [False]}]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_dfs = []\n",
    "\n",
    "for model in models:\n",
    "    clf_name = model['clf'].__name__\n",
    "    clf = model['clf']\n",
    "    params = model['params']\n",
    "    %time search = GridSearchCV(clf(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(X, y)\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    cv_df['clf_name'] = clf_name\n",
    "    cv_dfs.append(cv_df)\n",
    "    print(clf_name)\n",
    "    print(search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_eval_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.046851</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.587867</td>\n",
       "      <td>0.328908</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>MultiClass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              clf_name  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "45      LGBMClassifier         0.382114       0.046851         0.015592   \n",
       "62  CatBoostClassifier         0.587867       0.328908         0.006691   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_eval_metric  \n",
       "45                 0.9               2                 10               mae  \n",
       "62                 0.1               4                 30        MultiClass  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_df = pd.concat(cv_dfs).reset_index(drop=True)\n",
    "best_models = cvs_df[\n",
    "        (cvs_df.mean_fit_time == cvs_df.mean_fit_time.min()) |\n",
    "        #(cvs_df.mean_score_time == cvs_df.mean_score_time.min()) | \n",
    "        (cvs_df.mean_test_score == cvs_df.mean_test_score.max())]\n",
    "best_models = best_models[[\n",
    "        'clf_name',\n",
    "        'mean_test_score',\n",
    "        'mean_fit_time',\n",
    "        'mean_score_time',\n",
    "        'param_learning_rate',\n",
    "        'param_max_depth',\n",
    "        'param_n_estimators',\n",
    "        'param_eval_metric'\n",
    "]]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from functools import partial\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 40/40 [00:18<00:00,  2.12trial/s, best loss: -0.5822388993120701]\n",
      "name - xgbc\n",
      "loss - -0.5822388993120701\n",
      "eval_metric - mae\n",
      "learning_rate - 0.11686806096025022\n",
      "max_depth - 4\n",
      "n_estimators - 11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {'name':'xgbc', 'clf':XGBClassifier(), 'eval_metrics':['mlogloss', 'mae']}\n",
    "]\n",
    "\n",
    "def objective(params, pipe,  X_train, y_train):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(estimator=pipe, X=X_train, y=y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    clf = model['clf']\n",
    "    eval_metrics = model['eval_metrics']\n",
    "    pipe = Pipeline([(name, clf)])\n",
    "    search_space = {\n",
    "        name+'__eval_metric': hp.choice(label=\"eval_metric\", options=eval_metrics),\n",
    "        name+'__learning_rate' : hp.loguniform(label='learning_rate', low=np.log(0.04), high=np.log(0.5)),\n",
    "        name+'__max_depth' :  hp.choice(label=\"max_depth\", options=np.arange(2, 10, 1, dtype=int)),\n",
    "        name+'__n_estimators' : hp.choice(label=\"n_estimators\", options=np.arange(1, 100, 10, dtype=int))\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin( \n",
    "        fn=partial(objective, pipe=pipe, X_train=X, y_train=y),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=40,\n",
    "        trials=trials,\n",
    "        show_progressbar=True\n",
    "    )\n",
    "    print('name -', name)\n",
    "    print('loss -', trials.best_trial['result']['loss'])\n",
    "    for param_name in trials.best_trial['result']['params']:\n",
    "        print(param_name.split('__')[1], '-', trials.best_trial['result']['params'][param_name])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5641025641025641"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('cbc', CatBoostClassifier()),\n",
    "    ('lgbmc', LGBMClassifier()),\n",
    "    ('rfc', GradientBoostingClassifier()),\n",
    "    ('xgbc', XGBClassifier())\n",
    "]\n",
    "stacked = StackingClassifier(estimators=estimators)\n",
    "%time score = cross_val_score(estimator=stacked, X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 40/40 [06:37<00:00,  9.93s/trial, best loss: -0.575984990619137]\n",
      "name - gbc\n",
      "loss - -0.575984990619137\n",
      "criterion - friedman_mse\n",
      "learning_rate - 0.05464112510033956\n",
      "max_depth - 2\n",
      "n_estimators - 81\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 40/40 [00:19<00:00,  2.04trial/s, best loss: -0.5728580362726704]\n",
      "name - xgbc\n",
      "loss - -0.5728580362726704\n",
      "eval_metric - mae\n",
      "learning_rate - 0.10959516033840336\n",
      "max_depth - 2\n",
      "n_estimators - 61\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 40/40 [00:14<00:00,  2.86trial/s, best loss: -0.5766103814884304]\n",
      "name - lgbmc\n",
      "loss - -0.5766103814884304\n",
      "eval_metric - mlogloss\n",
      "learning_rate - 0.05042906798990702\n",
      "max_depth - 3\n",
      "n_estimators - 31\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 40/40 [00:31<00:00,  1.26trial/s, best loss: -0.5916197623514696]\n",
      "name - cbc\n",
      "loss - -0.5916197623514696\n",
      "eval_metric - MultiClass\n",
      "learning_rate - 0.18138887199062947\n",
      "max_depth - 2\n",
      "n_estimators - 41\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {'name':'gbc', 'clf':GradientBoostingClassifier(), \n",
    "     'metrics':{'param_name':'criterion','param_vals':['friedman_mse', 'mae']}},\n",
    "    {'name':'xgbc', 'clf':XGBClassifier(),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['mlogloss', 'mae']}},\n",
    "    {'name':'lgbmc', 'clf':LGBMClassifier(objective='multi:softprob'),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['mlogloss', 'mae']}},\n",
    "    {'name':'cbc', 'clf':CatBoostClassifier(loss_function='MultiClass'),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['MultiClass']}},\n",
    "]\n",
    "\n",
    "def objective(params, pipe,  X_train, y_train):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(estimator=pipe, X=X_train, y=y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "best_trials = {}\n",
    "\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    clf = model['clf']\n",
    "    param_name = model['metrics']['param_name']\n",
    "    param_vals = model['metrics']['param_vals']\n",
    "    pipe = Pipeline([(name, clf)])\n",
    "    search_space = {\n",
    "        name+'__'+param_name: hp.choice(label=param_name, options=param_vals),\n",
    "        name+'__learning_rate' : hp.loguniform(label='learning_rate', low=np.log(0.04), high=np.log(0.5)),\n",
    "        name+'__max_depth' :  hp.choice(label=\"max_depth\", options=np.arange(2, 10, 1, dtype=int)),\n",
    "        name+'__n_estimators' : hp.choice(label=\"n_estimators\", options=np.arange(1, 100, 10, dtype=int))\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin( \n",
    "        fn=partial(objective, pipe=pipe, X_train=X, y_train=y),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=40,\n",
    "        trials=trials,\n",
    "        show_progressbar=True\n",
    "    )\n",
    "    best_trials[name] = trials.best_trial\n",
    "    print('name -', name)\n",
    "    print('loss -', trials.best_trial['result']['loss'])\n",
    "    for param_name in trials.best_trial['result']['params']:\n",
    "        print(param_name.split('__')[1], '-', trials.best_trial['result']['params'][param_name])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5897435897435898"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = {'gbc':GradientBoostingClassifier, 'xgbc':XGBClassifier, 'lgbmc':LGBMClassifier, 'cbc':CatBoostClassifier}\n",
    "optimal_models = []\n",
    "for name in best_trials:\n",
    "    params = best_trials[name]['result']['params']\n",
    "    renamed_params = {}\n",
    "    for param_name in params:\n",
    "        renamed_name = param_name.split('__')[1]\n",
    "        renamed_params[renamed_name] = params[param_name]\n",
    "    model = clfs[name]\n",
    "    optimal_model = model(**renamed_params)\n",
    "    optimal_models.append((name, optimal_model))\n",
    "\n",
    "stacked = StackingClassifier(estimators=optimal_models)\n",
    "%time score = cross_val_score(estimator=stacked, X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэкинг моделей с оптимальными параметрами, показывает немного более лучший результат по метрике и гараздо лучший по времени обучения. Вывод- данный ансамблевый лучше применять на предподготовленных моделях с заранее подобранными оптимальными параметрами."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
