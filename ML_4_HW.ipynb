{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(link, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Wall time: 943 ms\n",
      "0.557848655409631 \n",
      "\n",
      "BaggingClassifier(n_estimators=100)\n",
      "Wall time: 1.82 s\n",
      "0.5616010006253909 \n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Wall time: 31.3 ms\n",
      "0.44903064415259536 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "clfs = [RandomForestClassifier(n_estimators=100), BaggingClassifier(n_estimators=100), DecisionTreeClassifier()]\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    %time cvs = cross_val_score(clf, X, y, scoring='accuracy', cv=3).mean()\n",
    "    print(cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат по метрике accuracy у RandomForestClassifier почти такой-же как и у BaggingClassifier, но скорость обучения быстрее в ~2 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, test_size=.3, size=1, seed=42):\n",
    "    df_res = df.sample(int(df.shape[0]*size)).copy() if size != 1 else df.copy()\n",
    "    X_res, y_res = df_res.iloc[:,:-1], df_res.iloc[:,-1]\n",
    "    X_res_train, X_res_test, y_res_train, y_res_test = train_test_split(X_res, y_res, test_size=test_size, random_state=seed)\n",
    "    return df_res, X_res, y_res, X_res_train, X_res_test, y_res_train, y_res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12) (1599, 11) (1119, 11) (480, 11)\n"
     ]
    }
   ],
   "source": [
    "df, X, y, X_train, X_test, y_train, y_test = split_df(data)\n",
    "print(df.shape, X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N = [10, 50, 100] + [n for n in range(200,5001,200)]\n",
    "scores = []\n",
    "\n",
    "for n in N:\n",
    "    clf = RandomForestClassifier(n_estimators=int(n), n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score_test = clf.score(X_test, y_test)\n",
    "    score_train = clf.score(X_train, y_train)\n",
    "    scores.append({'n':int(n), 'score_test':score_test, 'score_train':score_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c4cdac26a0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "plt.plot(scores_df.n, scores_df.score_test)\n",
    "#plt.plot(scores_df.n, scores_df.score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "Wall time: 8.04 s\n",
      "0.5697315830721004 \n",
      "\n",
      "XGBClassifier\n",
      "Wall time: 1.99 s\n",
      "0.5472335423197492 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "clfs = [{'name':'GradientBoostingClassifier', 'model':GradientBoostingClassifier()}, \n",
    "        {'name':'XGBClassifier', 'model':XGBClassifier(objective='multi:softprob', eval_metric='mlogloss')}]\n",
    "\n",
    "for clf in clfs:\n",
    "    clf_name = clf['name']\n",
    "    model = clf['model']\n",
    "    print(clf_name)\n",
    "    %time cvs = cross_val_score(model, X, y, scoring=\"accuracy\", cv=5).mean()\n",
    "    print(cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'init', 'learning_rate', 'loss', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_iter_no_change', 'presort', 'random_state', 'subsample', 'tol', 'validation_fraction', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['objective', 'use_label_encoder', 'base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'gpu_id', 'importance_type', 'interaction_constraints', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'monotone_constraints', 'n_estimators', 'n_jobs', 'num_parallel_tree', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'subsample', 'tree_method', 'validate_parameters', 'verbosity'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n",
      "GradientBoostingClassifier\n",
      "{'criterion': 'friedman_mse', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 30}\n",
      "Wall time: 7.33 s\n",
      "XGBClassifier\n",
      "{'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 20, 'objective': 'multi:softprob'}\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'clf': GradientBoostingClassifier,\n",
    "        'params': [{\n",
    "            'criterion': ['friedman_mse', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30], \n",
    "            'max_depth': [2, 3, 4]\n",
    "        }]\n",
    "    }, {\n",
    "        'clf': XGBClassifier,\n",
    "        'params': [{\n",
    "            'objective': ['multi:softprob'],\n",
    "            'eval_metric': ['mlogloss', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4]\n",
    "        }]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_dfs = []\n",
    "\n",
    "for model in models:\n",
    "    clf_name = model['clf'].__name__\n",
    "    clf = model['clf']\n",
    "    params = model['params']\n",
    "    %time search = GridSearchCV(clf(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(X, y)\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    cv_df['clf_name'] = clf_name\n",
    "    cv_dfs.append(cv_df)\n",
    "    print(clf_name)\n",
    "    print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_eval_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.408848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlogloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.557849</td>\n",
       "      <td>0.096069</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>mlogloss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.486933</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         clf_name  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "61  XGBClassifier         0.585991       0.408848         0.000000   \n",
       "63  XGBClassifier         0.557849       0.096069         0.007382   \n",
       "88  XGBClassifier         0.585991       0.486933         0.007210   \n",
       "\n",
       "   param_criterion param_learning_rate param_max_depth param_n_estimators  \\\n",
       "61             NaN                 0.1               4                 20   \n",
       "63             NaN                 0.5               2                 10   \n",
       "88             NaN                 0.1               4                 20   \n",
       "\n",
       "   param_eval_metric  \n",
       "61          mlogloss  \n",
       "63          mlogloss  \n",
       "88               mae  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_df = pd.concat(cv_dfs).reset_index(drop=True)\n",
    "best_models = cvs_df[\n",
    "        (cvs_df.mean_fit_time == cvs_df.mean_fit_time.min()) |\n",
    "        #(cvs_df.mean_score_time == cvs_df.mean_score_time.min()) | \n",
    "        (cvs_df.mean_test_score == cvs_df.mean_test_score.max())]\n",
    "best_models = best_models[[\n",
    "        'clf_name',\n",
    "        'mean_test_score',\n",
    "        'mean_fit_time',\n",
    "        'mean_score_time',\n",
    "        'param_criterion',\n",
    "        'param_learning_rate',\n",
    "        'param_max_depth',\n",
    "        'param_n_estimators',\n",
    "        'param_eval_metric'\n",
    "]]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier \n",
      "\n",
      "Wall time: 4.42 s\n",
      "cross_val_score -  0.541588492808005 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier \n",
      "\n",
      "Wall time: 1.21 s\n",
      "cross_val_score -  0.5284552845528455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(objective='multi:softprob', eval_metric='mlogloss'), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier \n",
      "\n",
      "Wall time: 1.07 s\n",
      "cross_val_score -  0.5284552845528455 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier \n",
      "\n",
      "Wall time: 20.4 s\n",
      "cross_val_score -  0.5328330206378987 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier\n",
    "print(model.__name__, '\\n')\n",
    "      \n",
    "%time cvs = cross_val_score(model(verbose=False), X, y, scoring=\"accuracy\", cv=3).mean()\n",
    "print('cross_val_score - ', cvs, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoostClassifier(verbose=False).fit(X,y).get_all_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "Wall time: 4.83 s\n",
      "LGBMClassifier\n",
      "{'eval_metric': 'mlogloss', 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 20, 'objective': 'multi:softprob'} \n",
      "\n",
      "Wall time: 3.2 s\n",
      "CatBoostClassifier\n",
      "{'eval_metric': 'MultiClass', 'learning_rate': 0.1, 'loss_function': 'MultiClass', 'max_depth': 4, 'n_estimators': 30, 'verbose': False} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'clf': LGBMClassifier,\n",
    "        'params': [{\n",
    "            'objective': ['multi:softprob'],\n",
    "            'eval_metric': ['mlogloss', 'mae'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4]}]\n",
    "    }, {\n",
    "        'clf': CatBoostClassifier,\n",
    "        'params': [{\n",
    "            'loss_function': ['MultiClass'],\n",
    "            'eval_metric': ['MultiClass'],\n",
    "            'learning_rate': [.1, .5, .9],\n",
    "            'n_estimators': [10, 20, 30],  \n",
    "            'max_depth': [2, 3, 4],\n",
    "            'verbose': [False]}]\n",
    "    }\n",
    "]\n",
    "\n",
    "cv_dfs = []\n",
    "\n",
    "for model in models:\n",
    "    clf_name = model['clf'].__name__\n",
    "    clf = model['clf']\n",
    "    params = model['params']\n",
    "    %time search = GridSearchCV(clf(), param_grid=params, scoring='accuracy', cv=3, n_jobs=-1).fit(X, y)\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    cv_df['clf_name'] = clf_name\n",
    "    cv_dfs.append(cv_df)\n",
    "    print(clf_name)\n",
    "    print(search.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf_name</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_eval_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.548468</td>\n",
       "      <td>0.052121</td>\n",
       "      <td>0.00672</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.587867</td>\n",
       "      <td>0.294592</td>\n",
       "      <td>0.01089</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>MultiClass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              clf_name  mean_test_score  mean_fit_time  mean_score_time  \\\n",
       "36      LGBMClassifier         0.548468       0.052121          0.00672   \n",
       "62  CatBoostClassifier         0.587867       0.294592          0.01089   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators param_eval_metric  \n",
       "36                 0.5               2                 10               mae  \n",
       "62                 0.1               4                 30        MultiClass  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs_df = pd.concat(cv_dfs).reset_index(drop=True)\n",
    "best_models = cvs_df[\n",
    "        (cvs_df.mean_fit_time == cvs_df.mean_fit_time.min()) |\n",
    "        #(cvs_df.mean_score_time == cvs_df.mean_score_time.min()) | \n",
    "        (cvs_df.mean_test_score == cvs_df.mean_test_score.max())]\n",
    "best_models = best_models[[\n",
    "        'clf_name',\n",
    "        'mean_test_score',\n",
    "        'mean_fit_time',\n",
    "        'mean_score_time',\n",
    "        'param_learning_rate',\n",
    "        'param_max_depth',\n",
    "        'param_n_estimators',\n",
    "        'param_eval_metric'\n",
    "]]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from functools import partial\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 40/40 [00:18<00:00,  2.20trial/s, best loss: -0.5803627267041901]\n",
      "name - xgbc\n",
      "loss - -0.5803627267041901\n",
      "eval_metric - mlogloss\n",
      "learning_rate - 0.1479200097500323\n",
      "max_depth - 6\n",
      "n_estimators - 11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {'name':'xgbc', 'clf':XGBClassifier(), 'eval_metrics':['mlogloss', 'mae']}\n",
    "]\n",
    "\n",
    "def objective(params, pipe,  X_train, y_train):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(estimator=pipe, X=X_train, y=y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    clf = model['clf']\n",
    "    eval_metrics = model['eval_metrics']\n",
    "    pipe = Pipeline([(name, clf)])\n",
    "    search_space = {\n",
    "        name+'__eval_metric': hp.choice(label=\"eval_metric\", options=eval_metrics),\n",
    "        name+'__learning_rate' : hp.loguniform(label='learning_rate', low=np.log(0.04), high=np.log(0.5)),\n",
    "        name+'__max_depth' :  hp.choice(label=\"max_depth\", options=np.arange(2, 10, 1, dtype=int)),\n",
    "        name+'__n_estimators' : hp.choice(label=\"n_estimators\", options=np.arange(1, 100, 10, dtype=int))\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin( \n",
    "        fn=partial(objective, pipe=pipe, X_train=X, y_train=y),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=40,\n",
    "        trials=trials,\n",
    "        show_progressbar=True\n",
    "    )\n",
    "    print('name -', name)\n",
    "    print('loss -', trials.best_trial['result']['loss'])\n",
    "    for param_name in trials.best_trial['result']['params']:\n",
    "        print(param_name.split('__')[1], '-', trials.best_trial['result']['params'][param_name])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5666041275797373"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('cbc', CatBoostClassifier()),\n",
    "    ('lgbmc', LGBMClassifier()),\n",
    "    ('rfc', GradientBoostingClassifier()),\n",
    "    ('xgbc', XGBClassifier())\n",
    "]\n",
    "stacked = StackingClassifier(estimators=estimators)\n",
    "%time score = cross_val_score(estimator=stacked, X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████| 40/40 [05:45<00:00,  8.65s/trial, best loss: -0.575984990619137]\n",
      "name - gbc\n",
      "loss - -0.575984990619137\n",
      "criterion - friedman_mse\n",
      "learning_rate - 0.04371211482448806\n",
      "max_depth - 2\n",
      "n_estimators - 91\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 40/40 [00:22<00:00,  1.77trial/s, best loss: -0.5797373358348968]\n",
      "name - xgbc\n",
      "loss - -0.5797373358348968\n",
      "eval_metric - mlogloss\n",
      "learning_rate - 0.044117644495022944\n",
      "max_depth - 5\n",
      "n_estimators - 21\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 40/40 [00:17<00:00,  2.24trial/s, best loss: -0.5766103814884302]\n",
      "name - lgbmc\n",
      "loss - -0.5766103814884302\n",
      "eval_metric - mae\n",
      "learning_rate - 0.09700525753870985\n",
      "max_depth - 3\n",
      "n_estimators - 11\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 40/40 [00:41<00:00,  1.05s/trial, best loss: -0.5916197623514696]\n",
      "name - cbc\n",
      "loss - -0.5916197623514696\n",
      "eval_metric - MultiClass\n",
      "learning_rate - 0.08220908947481331\n",
      "max_depth - 5\n",
      "n_estimators - 51\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {'name':'gbc', 'clf':GradientBoostingClassifier(), \n",
    "     'metrics':{'param_name':'criterion','param_vals':['friedman_mse', 'mae']}},\n",
    "    {'name':'xgbc', 'clf':XGBClassifier(),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['mlogloss', 'mae']}},\n",
    "    {'name':'lgbmc', 'clf':LGBMClassifier(objective='multi:softprob'),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['mlogloss', 'mae']}},\n",
    "    {'name':'cbc', 'clf':CatBoostClassifier(loss_function='MultiClass'),\n",
    "     'metrics':{'param_name':'eval_metric','param_vals':['MultiClass']}},\n",
    "]\n",
    "\n",
    "def objective(params, pipe,  X_train, y_train):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(estimator=pipe, X=X_train, y=y_train, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    return {'loss': -score.mean(), 'params': params, 'status': STATUS_OK}\n",
    "\n",
    "best_trials = {}\n",
    "\n",
    "for model in models:\n",
    "    name = model['name']\n",
    "    clf = model['clf']\n",
    "    param_name = model['metrics']['param_name']\n",
    "    param_vals = model['metrics']['param_vals']\n",
    "    pipe = Pipeline([(name, clf)])\n",
    "    search_space = {\n",
    "        name+'__'+param_name: hp.choice(label=param_name, options=param_vals),\n",
    "        name+'__learning_rate' : hp.loguniform(label='learning_rate', low=np.log(0.04), high=np.log(0.5)),\n",
    "        name+'__max_depth' :  hp.choice(label=\"max_depth\", options=np.arange(2, 10, 1, dtype=int)),\n",
    "        name+'__n_estimators' : hp.choice(label=\"n_estimators\", options=np.arange(1, 100, 10, dtype=int))\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin( \n",
    "        fn=partial(objective, pipe=pipe, X_train=X, y_train=y),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=40,\n",
    "        trials=trials,\n",
    "        show_progressbar=True\n",
    "    )\n",
    "    best_trials[name] = trials.best_trial\n",
    "    print('name -', name)\n",
    "    print('loss -', trials.best_trial['result']['loss'])\n",
    "    for param_name in trials.best_trial['result']['params']:\n",
    "        print(param_name.split('__')[1], '-', trials.best_trial['result']['params'][param_name])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5934959349593497"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = {'gbc':GradientBoostingClassifier, 'xgbc':XGBClassifier, 'lgbmc':LGBMClassifier, 'cbc':CatBoostClassifier}\n",
    "optimal_models = []\n",
    "for name in best_trials:\n",
    "    params = best_trials[name]['result']['params']\n",
    "    renamed_params = {}\n",
    "    for param_name in params:\n",
    "        renamed_name = param_name.split('__')[1]\n",
    "        renamed_params[renamed_name] = params[param_name]\n",
    "    model = clfs[name]\n",
    "    optimal_model = model(**renamed_params)\n",
    "    optimal_models.append((name, optimal_model))\n",
    "\n",
    "stacked = StackingClassifier(estimators=optimal_models)\n",
    "%time score = cross_val_score(estimator=stacked, X=X, y=y, scoring='accuracy', cv=3, n_jobs=-1).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стэкинг моделей с оптимальными параметрами, показывает более лучший результат по метрике и по времени обучения. Вывод- данный ансамблевый лучше применять на предподготовленных моделях с заранее подобранными оптимальными параметрами."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
